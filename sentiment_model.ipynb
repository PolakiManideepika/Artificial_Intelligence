{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7327f53-ae25-4645-bd56-eedb46ce3a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "df = pd.read_csv(\"customer_feedback_clean.csv\")\n",
    "\n",
    "if 'label' not in df.columns:\n",
    "    def simple_label(x):\n",
    "        x = x.lower()\n",
    "        if any(w in x for w in ['excellent','great','happy','satisfied','loved']):\n",
    "            return \"Positive\"\n",
    "        if any(w in x for w in ['delay','disappoint','refund','damaged','poor','wrong']):\n",
    "            return \"Negative\"\n",
    "        return \"Neutral\"\n",
    "    df['label'] = df['feedback'].apply(simple_label)\n",
    "    \n",
    "label2id = {\"Negative\":0,\"Neutral\":1,\"Positive\":2}\n",
    "id2label = {v:k for k,v in label2id.items()}\n",
    "df['label_id'] = df['label'].map(label2id)\n",
    "\n",
    "train_df, test_df = train_test_split(df[['processed','label_id']], test_size=0.2, random_state=42, stratify=df['label_id'])\n",
    "\n",
    "train_ds = Dataset.from_pandas(train_df.rename(columns={'processed':'text'}))\n",
    "test_ds  = Dataset.from_pandas(test_df.rename(columns={'processed':'text'}))\n",
    "\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch['text'], padding='max_length', truncation=True, max_length=128)\n",
    "\n",
    "train_ds = train_ds.map(tokenize, batched=True)\n",
    "test_ds  = test_ds.map(tokenize, batched=True)\n",
    "train_ds.set_format(type='torch', columns=['input_ids','attention_mask','label_id'])\n",
    "test_ds.set_format(type='torch', columns=['input_ids','attention_mask','label_id'])\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=3)\n",
    "\n",
    "def compute_metrics(p):\n",
    "    preds = np.argmax(p.predictions, axis=1)\n",
    "    labels = p.label_ids\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted', zero_division=0)\n",
    "    return {\"accuracy\": acc, \"precision\": prec, \"recall\": rec, \"f1\": f1}\n",
    "\n",
    "args = TrainingArguments(\n",
    "    \"distilbert-finetuned-sentiment\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=3,\n",
    "    save_total_limit=1,\n",
    "    logging_steps=10,\n",
    "    push_to_hub=False\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=test_ds,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "metrics = trainer.evaluate()\n",
    "print(metrics)\n",
    "model.save_pretrained(\"sentiment_model\")\n",
    "tokenizer.save_pretrained(\"sentiment_model\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
